{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hitenjain20/Grammar-Error-correction/blob/main/Encoder%20and%20decoder%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B-IxeASYoWlF"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import fbeta_score\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.layers import Embedding,LSTM, TimeDistributed, Dense, Bidirectional\n",
        "from tensorflow.keras.initializers import HeNormal, GlorotNormal, GlorotUniform\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYRqz8zipJoZ",
        "outputId": "dc5f6a1d-d904-4922-9f78-673d680c1ca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "F_LfkIDBpMhP"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Data/final_preprocessed_15.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EXyWw1IepYK-",
        "outputId": "a3ae5074-f1cd-4d00-e561-da8222979428"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-da992c7a-cafb-43a7-a790-ce5a295423fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>error</th>\n",
              "      <th>correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>And he took in my favorite subject like soccer .</td>\n",
              "      <td>And he took in my favorite subjects like soccer .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Actually , who let me know about Lang - was him .</td>\n",
              "      <td>Actually , he was the one who let me know about Lang - . .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>His Kanji is ability is much better than me .</td>\n",
              "      <td>His Kanji ability is much better than mine .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I heard a sentence last night when I watched TV .</td>\n",
              "      <td>I heard a sentence last night when I was watching TV .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>When you go uphill , you hvae to bend your back .</td>\n",
              "      <td>When you go uphill , you have to bend your back .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>When you are go smoothly , you have to be more modest .</td>\n",
              "      <td>When everything is going smoothly , you have to be more modest .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The making souvenir is a hard and interesting work .</td>\n",
              "      <td>Making souvenirs is a hard but interesting work .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>You know , you can take them at slot machine .</td>\n",
              "      <td>You know , you can ? them at a slot machine .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The third memory is the house we lived .</td>\n",
              "      <td>The third memory is the house where we lived .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I liked the winter Finland .</td>\n",
              "      <td>I liked Finland in the Winter .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>And I hope I like the summer Finland .</td>\n",
              "      <td>And I hope I will like Finland in the Summer .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>If only I had black dense curtains .</td>\n",
              "      <td>If only I had dense black curtains .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>I had been wondering what she was doing .</td>\n",
              "      <td>I had been wondering what she was has been doing .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>It said that was disappointing .</td>\n",
              "      <td>It said that it was disappointing .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Old and not beautiful . . . . .</td>\n",
              "      <td>Old and not beautiful . . . . .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Still she has not recovered from them ?</td>\n",
              "      <td>she still has not recovered from them ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>OK , let is all for my first entry .</td>\n",
              "      <td>OK , that is all for my first entry .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Before , I went to a library .</td>\n",
              "      <td>Before , I went to the library .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>On the way I had a headache .</td>\n",
              "      <td>On the way I got a headache .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>If my sentences are not practical correct them .</td>\n",
              "      <td>If my sentences are not practical , please correct them .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Well , there remains to get it and check it out .</td>\n",
              "      <td>Well , I just have to get it and check it out .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Cooking is not her profession , she is a housewife .</td>\n",
              "      <td>Cooking is not her profession , but rather , she is a housewife .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>I rather be working outside than be a housewife .</td>\n",
              "      <td>I would rather be working outside than be a housewife .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>I think it is about for one and half year .</td>\n",
              "      <td>I think it is been about one and half years now .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>This is my first time to write diary on the internet .</td>\n",
              "      <td>This is my first time writing a diary on the internet .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>I hope someone see my diary and correct it .</td>\n",
              "      <td>I hope someone will see my diary and correct it .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>I watched DVD Grey is anatomy today .</td>\n",
              "      <td>I watched a DVD of Grey is anatomy today .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Actually I keep watching it these days .</td>\n",
              "      <td>Actually I watch it a lot these days .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>So there are a lot to see .</td>\n",
              "      <td>So there is a lot to see .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>I do not know medical word in English very much .</td>\n",
              "      <td>I do not know all the medical words in English .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>But I can study English through this .</td>\n",
              "      <td>But I can study English with it .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>And I think it is fun , right ?</td>\n",
              "      <td>And I think it is fun , right ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>And I am eating a banana every day for my health .</td>\n",
              "      <td>I am eating a banana every day for my health .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>The banana is gather in my stomach and gives me energy .</td>\n",
              "      <td>Bananas gives me energy .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>I will introduce about my dog , Tiara .</td>\n",
              "      <td>I will introduce my dog , Tiara .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>She is a golden retriever and she is years old .</td>\n",
              "      <td>She is an year old golden retriever</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Her fur is beautiful amber and soft .</td>\n",
              "      <td>Her fur is a beautiful amber colour and is soft .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>When she is basking she looks very comfortable .</td>\n",
              "      <td>When she is basking she looks very content .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>however , I hoped rain because it is too hot .</td>\n",
              "      <td>However , I hoped it would rain today because it is too hot .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>I saw a news on Yahoo yesterday .</td>\n",
              "      <td>I saw a news article on Yahoo yesterday .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>By contrast , men in eastern countries most dress up .</td>\n",
              "      <td>By contrast , men in eastern countries dress up more .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Except a shirt and a jean , we usually wear an accessory .</td>\n",
              "      <td>Apart from a shirt and jeans , we usually wear an accessory .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>It almost cost a whole morning .</td>\n",
              "      <td>It almost cost me a whole morning .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>I have to watch the NBA final game .</td>\n",
              "      <td>I have to watch the NBA is final game .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>I like you give me any commets and opinoins too .</td>\n",
              "      <td>I like you give me any comments and opinions too .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>I really like to discuss .</td>\n",
              "      <td>I would really like to discuss .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>When I came back home from working today .</td>\n",
              "      <td>When I came back home from work today , my son had diarrhea .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>It was like a warter and son is hip became red .</td>\n",
              "      <td>It was like water and his bottom was red .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Tomorrow I will go to hometown .</td>\n",
              "      <td>We were planning to go to my hometown tomorrow .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>We are ready to go out .</td>\n",
              "      <td>We were all ready to go .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da992c7a-cafb-43a7-a790-ce5a295423fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da992c7a-cafb-43a7-a790-ce5a295423fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da992c7a-cafb-43a7-a790-ce5a295423fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                         error                                                            correct\n",
              "0             And he took in my favorite subject like soccer .                  And he took in my favorite subjects like soccer .\n",
              "1            Actually , who let me know about Lang - was him .         Actually , he was the one who let me know about Lang - . .\n",
              "2                His Kanji is ability is much better than me .                       His Kanji ability is much better than mine .\n",
              "3            I heard a sentence last night when I watched TV .             I heard a sentence last night when I was watching TV .\n",
              "4            When you go uphill , you hvae to bend your back .                  When you go uphill , you have to bend your back .\n",
              "5      When you are go smoothly , you have to be more modest .   When everything is going smoothly , you have to be more modest .\n",
              "6         The making souvenir is a hard and interesting work .                  Making souvenirs is a hard but interesting work .\n",
              "7               You know , you can take them at slot machine .                      You know , you can ? them at a slot machine .\n",
              "8                     The third memory is the house we lived .                     The third memory is the house where we lived .\n",
              "9                                 I liked the winter Finland .                                    I liked Finland in the Winter .\n",
              "10                      And I hope I like the summer Finland .                     And I hope I will like Finland in the Summer .\n",
              "11                        If only I had black dense curtains .                               If only I had dense black curtains .\n",
              "12                   I had been wondering what she was doing .                 I had been wondering what she was has been doing .\n",
              "13                            It said that was disappointing .                                It said that it was disappointing .\n",
              "14                             Old and not beautiful . . . . .                                   Old and not beautiful . . . . . \n",
              "15                     Still she has not recovered from them ?                            she still has not recovered from them ?\n",
              "16                        OK , let is all for my first entry .                              OK , that is all for my first entry .\n",
              "17                              Before , I went to a library .                                   Before , I went to the library .\n",
              "18                               On the way I had a headache .                                      On the way I got a headache .\n",
              "19            If my sentences are not practical correct them .          If my sentences are not practical , please correct them .\n",
              "20           Well , there remains to get it and check it out .                    Well , I just have to get it and check it out .\n",
              "21        Cooking is not her profession , she is a housewife .  Cooking is not her profession , but rather , she is a housewife .\n",
              "22           I rather be working outside than be a housewife .            I would rather be working outside than be a housewife .\n",
              "23                 I think it is about for one and half year .                  I think it is been about one and half years now .\n",
              "24      This is my first time to write diary on the internet .            This is my first time writing a diary on the internet .\n",
              "25                I hope someone see my diary and correct it .                  I hope someone will see my diary and correct it .\n",
              "26                       I watched DVD Grey is anatomy today .                         I watched a DVD of Grey is anatomy today .\n",
              "27                    Actually I keep watching it these days .                             Actually I watch it a lot these days .\n",
              "28                                 So there are a lot to see .                                         So there is a lot to see .\n",
              "29           I do not know medical word in English very much .                   I do not know all the medical words in English .\n",
              "30                      But I can study English through this .                                  But I can study English with it .\n",
              "31                             And I think it is fun , right ?                                   And I think it is fun , right ? \n",
              "32          And I am eating a banana every day for my health .                     I am eating a banana every day for my health .\n",
              "33    The banana is gather in my stomach and gives me energy .                                          Bananas gives me energy .\n",
              "34                     I will introduce about my dog , Tiara .                                  I will introduce my dog , Tiara .\n",
              "35            She is a golden retriever and she is years old .                                She is an year old golden retriever\n",
              "36                       Her fur is beautiful amber and soft .                  Her fur is a beautiful amber colour and is soft .\n",
              "37            When she is basking she looks very comfortable .                       When she is basking she looks very content .\n",
              "38              however , I hoped rain because it is too hot .      However , I hoped it would rain today because it is too hot .\n",
              "39                           I saw a news on Yahoo yesterday .                          I saw a news article on Yahoo yesterday .\n",
              "40      By contrast , men in eastern countries most dress up .             By contrast , men in eastern countries dress up more .\n",
              "41  Except a shirt and a jean , we usually wear an accessory .      Apart from a shirt and jeans , we usually wear an accessory .\n",
              "42                            It almost cost a whole morning .                                It almost cost me a whole morning .\n",
              "43                        I have to watch the NBA final game .                            I have to watch the NBA is final game .\n",
              "44           I like you give me any commets and opinoins too .                 I like you give me any comments and opinions too .\n",
              "45                                  I really like to discuss .                                   I would really like to discuss .\n",
              "46                  When I came back home from working today .      When I came back home from work today , my son had diarrhea .\n",
              "47            It was like a warter and son is hip became red .                         It was like water and his bottom was red .\n",
              "48                            Tomorrow I will go to hometown .                   We were planning to go to my hometown tomorrow .\n",
              "49                                    We are ready to go out .                                          We were all ready to go ."
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "pd.options.display.max_colwidth = 500\n",
        "data[:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NwDxOfqKpa6g",
        "outputId": "15d717e6-6163-4d96-9cb1-2fb66f87dfcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9f67d5e9-352f-4e11-92db-dc1b84aa1efa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>error</th>\n",
              "      <th>correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>I am listening to music with the commuter train .</td>\n",
              "      <td>I am listening to music on the commuter train .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Today , I listen the music , it looks like in the cafe .</td>\n",
              "      <td>Today , I listen the music , it feels like I am in a cafe .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Spring is very exciting season .</td>\n",
              "      <td>Spring is a very exciting season .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Japanese school , work starts spring .</td>\n",
              "      <td>In Japan , the new school and work year starts in spring .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>I hope to get any quarifications in english .</td>\n",
              "      <td>I hope to become qualified in English .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>I hope to get my new promotions .</td>\n",
              "      <td>I hope to get a new promotion .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>Everyday starts new thinngs to try .</td>\n",
              "      <td>Everyday , there are new things to try .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>. . . No , extremely sometimes .</td>\n",
              "      <td>. . . No , very frequently .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>Since today , I am going to try write a diary ! !</td>\n",
              "      <td>Starting today , I am going to try write a diary everyday ! !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>Today is nothing specal to write ! !</td>\n",
              "      <td>Today has nothing specal to write ! !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>It is kind of Tai - wan stayle massage .</td>\n",
              "      <td>It is a kind of Tai - wan style massage .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>After that , I went to a fittness club which has bedrock bathing .</td>\n",
              "      <td>After that , I went to a fitness club which has bedrock bathing .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>I feel relax to take a bedrock bath</td>\n",
              "      <td>I felt relaxed to take a bedrock bath</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>I am went to Sendai to business trip today .</td>\n",
              "      <td>I went to Sendai as a business trip today .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>The special product in Sendai is a cow tongue .</td>\n",
              "      <td>The special product of Sendai is a cow is tongue .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>I bought it and ate at home .</td>\n",
              "      <td>I bought it and ate it at home .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>I want to eat its cow tongue again .</td>\n",
              "      <td>I want to eat this cow is tongue again .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>The daughter was woken up by my wife .</td>\n",
              "      <td>My daughter She was woken up by my wife .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>The wife was woken up by my stertor .</td>\n",
              "      <td>The wife was woken up by my stertor snoring .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>Where to do it and when we should leave is not decided yet !</td>\n",
              "      <td>Where to hold it and when we should leave has not been decided yet !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>And I want to live my life on my own pace .</td>\n",
              "      <td>And I want to live my life at my own pace .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>Because when I finished my classes , homeworks or jobs etc . . .</td>\n",
              "      <td>Because when I have finished my classes , homework or jobs etc . . .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>It is nearly pm when I back home .</td>\n",
              "      <td>It is nearly pm when I get back home .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>It is nearlly pm .</td>\n",
              "      <td>It is nearly pm .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>These days I suffered many unhappy things .</td>\n",
              "      <td>I have been suffering many unhappy things these days .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>I do not know how to master this language well . . .</td>\n",
              "      <td>I do not know how to master this language . . .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>I should to study again .</td>\n",
              "      <td>I should study again .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>I am got up at thirty past am in Japan .</td>\n",
              "      <td>I got up at am in Japan .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>I hope you make many friends of the lang - .</td>\n",
              "      <td>I hope to make many friends on lang - .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>Election will be done Augst .</td>\n",
              "      <td>Elections will be held on August th .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>Mayer is cheering Hamada minister of defence .</td>\n",
              "      <td>The Mayer is supporting Hamada for the minister of defense .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>Hamada birong to Liberal Democratic Party .</td>\n",
              "      <td>Hamada belong is to the Liberal Democratic Party .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>This time they may be lost adoministration .</td>\n",
              "      <td>This time they may lose administration .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>Democratic Party has more many supporters than them .</td>\n",
              "      <td>The Democratic Party has more supporters than they do .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>Mayer is busy with election campaign and his own work .</td>\n",
              "      <td>The Mayer is busy with the election campaign as well as his own work .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>I am going to do everyting for help him as his secretary .</td>\n",
              "      <td>I am going to helping him with his work as his secretary .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>I went to Kanazawa university festival with my American friend .</td>\n",
              "      <td>I went to a Kanazawa University festival with my American friend .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>I made good friend with Vietnamese .</td>\n",
              "      <td>I made a good friend with a Vietnamese .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>And we had a dinner with my another friends .</td>\n",
              "      <td>And we had dinner with my other friends .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>It is a amazing day today .</td>\n",
              "      <td>. Today was an amazing day .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>It is made of spnge It is cute .</td>\n",
              "      <td>It is made of sponge It is cute .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>I will enter the Berklee in the fall semester this year .</td>\n",
              "      <td>I will enter go to Berklee in the fall semester this year .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>But I have two worries .</td>\n",
              "      <td>However I have two worries .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>One of them is that my English is very clumsy yet .</td>\n",
              "      <td>One of them is that my English is still very clumsy .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>Another is high - priced tuition .</td>\n",
              "      <td>Another is the high - priced tuition fees .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>The Berklee do not requires a TOEFL score .</td>\n",
              "      <td>Berklee do not requires a TOEFL score .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Many assignments are given to me everyday .</td>\n",
              "      <td>I have a lot of assignments everyday .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>I am laerning English , but it is really difficult for me !</td>\n",
              "      <td>I am learning English , but it is really difficult for me !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>I was very scary because I had been very healthy so far .</td>\n",
              "      <td>I was very scared because I had been very healthy so far .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>I am still in the is .</td>\n",
              "      <td>I am still in my is .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f67d5e9-352f-4e11-92db-dc1b84aa1efa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f67d5e9-352f-4e11-92db-dc1b84aa1efa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f67d5e9-352f-4e11-92db-dc1b84aa1efa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                                 error                                                                 correct\n",
              "50                   I am listening to music with the commuter train .                         I am listening to music on the commuter train .\n",
              "51            Today , I listen the music , it looks like in the cafe .             Today , I listen the music , it feels like I am in a cafe .\n",
              "52                                    Spring is very exciting season .                                      Spring is a very exciting season .\n",
              "53                              Japanese school , work starts spring .              In Japan , the new school and work year starts in spring .\n",
              "54                       I hope to get any quarifications in english .                                 I hope to become qualified in English .\n",
              "55                                   I hope to get my new promotions .                                         I hope to get a new promotion .\n",
              "56                                Everyday starts new thinngs to try .                                Everyday , there are new things to try .\n",
              "57                                    . . . No , extremely sometimes .                                            . . . No , very frequently .\n",
              "58                   Since today , I am going to try write a diary ! !           Starting today , I am going to try write a diary everyday ! !\n",
              "59                                Today is nothing specal to write ! !                                   Today has nothing specal to write ! !\n",
              "60                            It is kind of Tai - wan stayle massage .                               It is a kind of Tai - wan style massage .\n",
              "61  After that , I went to a fittness club which has bedrock bathing .       After that , I went to a fitness club which has bedrock bathing .\n",
              "62                                I feel relax to take a bedrock bath                                   I felt relaxed to take a bedrock bath \n",
              "63                        I am went to Sendai to business trip today .                             I went to Sendai as a business trip today .\n",
              "64                     The special product in Sendai is a cow tongue .                      The special product of Sendai is a cow is tongue .\n",
              "65                                       I bought it and ate at home .                                        I bought it and ate it at home .\n",
              "66                                I want to eat its cow tongue again .                                I want to eat this cow is tongue again .\n",
              "67                              The daughter was woken up by my wife .                               My daughter She was woken up by my wife .\n",
              "68                               The wife was woken up by my stertor .                           The wife was woken up by my stertor snoring .\n",
              "69        Where to do it and when we should leave is not decided yet !    Where to hold it and when we should leave has not been decided yet !\n",
              "70                         And I want to live my life on my own pace .                             And I want to live my life at my own pace .\n",
              "71    Because when I finished my classes , homeworks or jobs etc . . .    Because when I have finished my classes , homework or jobs etc . . .\n",
              "72                                  It is nearly pm when I back home .                                  It is nearly pm when I get back home .\n",
              "73                                                  It is nearlly pm .                                                       It is nearly pm .\n",
              "74                         These days I suffered many unhappy things .                  I have been suffering many unhappy things these days .\n",
              "75                I do not know how to master this language well . . .                         I do not know how to master this language . . .\n",
              "76                                           I should to study again .                                                  I should study again .\n",
              "77                            I am got up at thirty past am in Japan .                                               I got up at am in Japan .\n",
              "78                        I hope you make many friends of the lang - .                                 I hope to make many friends on lang - .\n",
              "79                                       Election will be done Augst .                                   Elections will be held on August th .\n",
              "80                      Mayer is cheering Hamada minister of defence .            The Mayer is supporting Hamada for the minister of defense .\n",
              "81                         Hamada birong to Liberal Democratic Party .                      Hamada belong is to the Liberal Democratic Party .\n",
              "82                        This time they may be lost adoministration .                                This time they may lose administration .\n",
              "83               Democratic Party has more many supporters than them .                 The Democratic Party has more supporters than they do .\n",
              "84             Mayer is busy with election campaign and his own work .  The Mayer is busy with the election campaign as well as his own work .\n",
              "85          I am going to do everyting for help him as his secretary .              I am going to helping him with his work as his secretary .\n",
              "86    I went to Kanazawa university festival with my American friend .      I went to a Kanazawa University festival with my American friend .\n",
              "87                                I made good friend with Vietnamese .                                I made a good friend with a Vietnamese .\n",
              "88                       And we had a dinner with my another friends .                               And we had dinner with my other friends .\n",
              "89                                         It is a amazing day today .                                            . Today was an amazing day .\n",
              "90                                    It is made of spnge It is cute .                                       It is made of sponge It is cute .\n",
              "91           I will enter the Berklee in the fall semester this year .             I will enter go to Berklee in the fall semester this year .\n",
              "92                                            But I have two worries .                                            However I have two worries .\n",
              "93                 One of them is that my English is very clumsy yet .                   One of them is that my English is still very clumsy .\n",
              "94                                  Another is high - priced tuition .                             Another is the high - priced tuition fees .\n",
              "95                         The Berklee do not requires a TOEFL score .                                 Berklee do not requires a TOEFL score .\n",
              "96                         Many assignments are given to me everyday .                                  I have a lot of assignments everyday .\n",
              "97         I am laerning English , but it is really difficult for me !             I am learning English , but it is really difficult for me !\n",
              "98           I was very scary because I had been very healthy so far .              I was very scared because I had been very healthy so far .\n",
              "99                                              I am still in the is .                                                   I am still in my is ."
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data[50:100]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jbPbbrFapgOj"
      },
      "outputs": [],
      "source": [
        "def preprocess(t, add_start_token, add_end_token):\n",
        "\n",
        "  if add_start_token == True and add_end_token == False:\n",
        "    t = '<start>'+' '+t\n",
        "  if add_start_token == False and add_end_token == True:\n",
        "    t = t+' '+'<end>'\n",
        "  if add_start_token == True and add_end_token == True:\n",
        "    t = '<start>'+' '+t+' '+'<end>'\n",
        "\n",
        "  t = re.sub(' +', ' ', t)\n",
        "  return t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fGvMY9s-pi0Y"
      },
      "outputs": [],
      "source": [
        "encoder_input = [preprocess(line, add_start_token= True, add_end_token=True) for line in data['error']]\n",
        "decoder_input = [preprocess(line, add_start_token= True, add_end_token=False) for line in data['correct']]\n",
        "decoder_output = [preprocess(line, add_start_token= False, add_end_token=True) for line in data['correct']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqa0djjVplAh",
        "outputId": "a748c83d-5bdc-4e4b-9a2c-3ae56abdc5ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> And he took in my favorite subject like soccer . <end>\n",
            "<start> And he took in my favorite subjects like soccer .\n",
            "And he took in my favorite subjects like soccer . <end>\n"
          ]
        }
      ],
      "source": [
        "print(encoder_input[0])\n",
        "print(decoder_input[0])\n",
        "print(decoder_output[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4S39uhTt_-A",
        "outputId": "58edc5c3-ffd5-470a-d0c4-586c74e83c2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(289572, 17)\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer(filters='', split=\" \")\n",
        "tokenizer.fit_on_texts(encoder_input)\n",
        "word_index = tokenizer.word_index #vocabulary\n",
        "\n",
        "max_length = max([ len(row.split(\" \")) for row in encoder_input ])\n",
        "INPUT_ENCODER_LENGTH = max_length\n",
        "\n",
        "enc_input_encoded = tokenizer.texts_to_sequences(encoder_input)\n",
        "enc_input_padded= pad_sequences(enc_input_encoded, maxlen=INPUT_ENCODER_LENGTH, padding=\"post\")\n",
        "\n",
        "print(enc_input_padded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rOgaJqLuBAk",
        "outputId": "619d7e49-2f49-4049-c768-8f706a8ac3ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> And he took in my favorite subject like soccer . <end>\n",
            "[  1  11  46 177  13  10 281 901  39 619   3   2   0   0   0   0   0]\n"
          ]
        }
      ],
      "source": [
        "print(encoder_input[0])\n",
        "print(enc_input_padded[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LgNEXzaUuB8g"
      },
      "outputs": [],
      "source": [
        "decoder_data = decoder_input.copy()\n",
        "decoder_data.extend(decoder_output)\n",
        "\n",
        "out_tokenizer = Tokenizer(filters='', split=\" \")\n",
        "out_tokenizer.fit_on_texts(decoder_data)\n",
        "word_index = out_tokenizer.word_index #vocabulary\n",
        "\n",
        "max_length = max([ len(row.split(\" \")) for row in decoder_input ])\n",
        "INPUT_DECODER_LENGTH = max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWBHh681yF89",
        "outputId": "bd21233a-4173-4404-e033-6c21adbeb51f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(289572, 29)\n"
          ]
        }
      ],
      "source": [
        "dec_input_encoded = out_tokenizer.texts_to_sequences(decoder_input)\n",
        "dec_input_padded= pad_sequences(dec_input_encoded, maxlen=INPUT_DECODER_LENGTH, padding=\"post\", truncating = \"post\")\n",
        "\n",
        "print(dec_input_padded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSM9ZvBJuC7S",
        "outputId": "3f7b3233-e5fa-4233-88e9-a0fd2ce8f732"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> And he took in my favorite subjects like soccer .\n",
            "[   3   12   46  178   13   10  266 1490   41  610    1    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0]\n"
          ]
        }
      ],
      "source": [
        "print(decoder_input[0])\n",
        "print(dec_input_padded[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aM8sD1S2uD5-",
        "outputId": "0b4e5f8b-37c3-4ca8-edd1-24404091e60b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(289572, 29)\n"
          ]
        }
      ],
      "source": [
        "dec_output_encoded = out_tokenizer.texts_to_sequences(decoder_output)\n",
        "dec_output_padded= pad_sequences(dec_output_encoded, maxlen=INPUT_DECODER_LENGTH, padding=\"post\", truncating = \"post\")\n",
        "\n",
        "print(dec_output_padded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7O20fe_YrRHr",
        "outputId": "d6f5d7a9-72e7-40c1-ce2b-12dff540c5b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-07 12:49:30--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --header=\"Host: dl.fbaipublicfiles.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9,kn;q=0.8\" --header=\"Referer: https://fasttext.cc/\" \"https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\" -c -O 'wiki-news-300d-1M.vec.zip'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3stPMCfttfm2",
        "outputId": "58a9c40a-acc5-4f02-950a-1835e1b36451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  wiki-news-300d-1M.vec.zip\n",
            "replace wiki-news-300d-1M.vec? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip wiki-news-300d-1M.vec.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RB9zqHA9uhWF"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "\n",
        "def load_vectors(fname):\n",
        "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "    n, d = map(int, fin.readline().split())\n",
        "    data = {}\n",
        "    for line in fin:\n",
        "        tokens = line.rstrip().split(' ')\n",
        "        data[tokens[0]] = np.asarray(tokens[1:])#map(float, tokens[1:])\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ET9G2FPJukK3"
      },
      "outputs": [],
      "source": [
        "embedding_index = load_vectors('wiki-news-300d-1M.vec')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xD5EfnqumF_"
      },
      "outputs": [],
      "source": [
        "word_index = tokenizer.word_index\n",
        "num_tokens = len(word_index) + 2\n",
        "embedding_dim = 300\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "\n",
        "    if type(embedding_vector) == np.ndarray and embedding_vector.shape[0] == 300:  \n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))\n",
        "np.save('/content/drive/MyDrive/Data/in_embedding.npy', embedding_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3evyYSyu6h5"
      },
      "outputs": [],
      "source": [
        "word_index = out_tokenizer.word_index\n",
        "num_tokens = len(word_index) + 2\n",
        "embedding_dim = 300\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "\n",
        "    if type(embedding_vector) == np.ndarray and embedding_vector.shape[0] == 300:  \n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))\n",
        "np.save('/content/drive/MyDrive/Data/out_embedding.npy', embedding_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5NeYMAsAvbyr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6563c64-36c4-4d9e-96fb-ea4d5983abf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(52482, 300) (41170, 300)\n"
          ]
        }
      ],
      "source": [
        "in_embedding_matrix = np.load('/content/drive/MyDrive/Data/in_embedding.npy')\n",
        "out_embedding_matrix = np.load('/content/drive/MyDrive/Data/out_embedding.npy')\n",
        "print(in_embedding_matrix.shape, out_embedding_matrix.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DVdisJbkv2Q1"
      },
      "outputs": [],
      "source": [
        "#Encoder\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
        "        super().__init__()\n",
        "        self.vocab_size = inp_vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.lstm_units = lstm_size\n",
        "        self.input_length = input_length\n",
        "\n",
        "\n",
        "    def build(self, input_sequence):\n",
        "        #self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_size, input_length=self.input_length, \n",
        "        #                           #embeddings_initializer=keras.initializers.Constant(in_embedding_matrix), mask_zero=True, \n",
        "        #                           weights = [in_embedding_matrix], mask_zero=True, \n",
        "        #                           trainable = False, name=\"embedding_layer_encoder\")\n",
        "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_size, input_length=self.input_length,\n",
        "                           mask_zero=True, name=\"embedding_layer_encoder\")\n",
        "        self.lstm = LSTM(self.lstm_units, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
        "\n",
        "    def call(self,input_sequence,states, training = True):\n",
        "        input_embedding = self.embedding(input_sequence)   #(batch_size, length of input array, embedding_size)\n",
        "        self.lstm_output, self.state_h, self.state_c = self.lstm(input_embedding, initial_state = states)         \n",
        "        return self.lstm_output,self.state_h, self.state_c\n",
        "\n",
        "    \n",
        "    def initialize_states(self,batch_size):\n",
        "      initializer = GlorotNormal()\n",
        "      lstm_state_h = initializer(shape=(batch_size, self.lstm_units))#tf.zeros((batch_size, self.lstm_units), dtype=tf.dtypes.float32, name=\"Encoder_LSTM_hidden_state\")\n",
        "      lstm_state_c = initializer(shape=(batch_size, self.lstm_units))#tf.zeros((batch_size, self.lstm_units), dtype=tf.dtypes.float32, name=\"Encoder_LSTM_cell_state\")\n",
        "      return lstm_state_h, lstm_state_c\n",
        "\n",
        "#DECODER\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,out_vocab_size,embedding_size,lstm_size,input_length):\n",
        "        super().__init__()\n",
        "        self.vocab_size = out_vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.lstm_units = lstm_size\n",
        "        self.input_length = input_length\n",
        "\n",
        "\n",
        "    def build(self,input_sequence):\n",
        "        #self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_size, input_length=self.input_length, \n",
        "        #                           #embeddings_initializer=keras.initializers.Constant(out_embedding_matrix), \n",
        "        #                           weights = [out_embedding_matrix], mask_zero=True, \n",
        "        #                           trainable = False, name=\"embedding_layer_decoder\")\n",
        "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_size, input_length=self.input_length,\n",
        "                           mask_zero=True, name=\"embedding_layer_decoder\") \n",
        "        self.lstm = LSTM(self.lstm_units, return_state=True, return_sequences=True, name=\"Decoder_LSTM\")\n",
        "\n",
        "\n",
        "    def call(self,input_sequence,initial_states, training = True):\n",
        "\n",
        "        input_embedding = self.embedding(input_sequence)\n",
        "        self.lstm_output, self.state_h, self.state_c = self.lstm(input_embedding, initial_state=initial_states)\n",
        "        return self.lstm_output,self.state_h, self.state_c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "JgrG1NJtv-2a"
      },
      "outputs": [],
      "source": [
        "class Encoder_decoder(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, encoder_inputs_length,decoder_inputs_length, output_vocab_size):\n",
        "\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(INPUT_VOCAB_SIZE, embedding_size = 256, lstm_size= 1200 , input_length= INPUT_ENCODER_LENGTH)\n",
        "        self.decoder = Decoder(OUTPUT_VOCAB_SIZE, embedding_size = 256, lstm_size = 1200, input_length = None)\n",
        "        self.dense = Dense(output_vocab_size)#, activation = 'softmax')\n",
        "    \n",
        "    def call(self,data):\n",
        "        input, output = data[0], data[1]\n",
        "        states = self.encoder.initialize_states(input.shape[0])\n",
        "        encoder_output,encoder_final_state_h,encoder_final_state_c = self.encoder(input, states)\n",
        "        decoder_output,decoder_state_h,decoder_state_c = self.decoder(output,[encoder_final_state_h,encoder_final_state_c])\n",
        "        outputs = self.dense(decoder_output)\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Zq2DehiYwCAa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c929a15-644e-45f6-d1b1-eeab6d29b917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52481 17 41169 29 16\n"
          ]
        }
      ],
      "source": [
        "INPUT_VOCAB_SIZE = len(list(tokenizer.word_index)) +1 #for zero padding +OOV\n",
        "OUTPUT_VOCAB_SIZE = len(list(out_tokenizer.word_index)) +1 #for zero padding + OOV\n",
        "BATCH_SIZE = 16\n",
        "print(INPUT_VOCAB_SIZE, INPUT_ENCODER_LENGTH, OUTPUT_VOCAB_SIZE, INPUT_DECODER_LENGTH, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "j3hxsLcNwEq-"
      },
      "outputs": [],
      "source": [
        "NUMBER_OF_DATAPOINTS = 10000\n",
        "\n",
        "tf.random.set_seed(32)\n",
        "\n",
        "encoder_input_datatset = tf.data.Dataset.from_tensor_slices(enc_input_padded)\n",
        "decoder_input_datatset = tf.data.Dataset.from_tensor_slices(dec_input_padded)\n",
        "decoder_output_datatset = tf.data.Dataset.from_tensor_slices(dec_output_padded)\n",
        "\n",
        "full_dataset =  tf.data.Dataset.zip( ((encoder_input_datatset.take(NUMBER_OF_DATAPOINTS), decoder_input_datatset.take(NUMBER_OF_DATAPOINTS)), decoder_output_datatset.take(NUMBER_OF_DATAPOINTS) ) ).shuffle(1000) #encoder_input_datatset.take(NUMBER_OF_DATAPOINTS).repeat(2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2PyHEOySwLRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba050ff2-789b-4541-c136-e025a9db2e56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset shapes: (((None, 17), (None, 29)), (None, 29)), types: ((tf.int32, tf.int32), tf.int32)> <BatchDataset shapes: (((None, 17), (None, 29)), (None, 29)), types: ((tf.int32, tf.int32), tf.int32)>\n"
          ]
        }
      ],
      "source": [
        "test_dataset = full_dataset.take(50).batch(32)\n",
        "train_dataset = full_dataset.skip(50).batch(32)\n",
        "\n",
        "print(train_dataset, test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "G5w8IeciwN03"
      },
      "outputs": [],
      "source": [
        "#LEARNING RATE SCHEDULER: Decay learning rate after 15 epochs\n",
        "def scheduler(epoch, lr):\n",
        "   if epoch < 1:\n",
        "     return lr   \n",
        "   else:\n",
        "     return lr * tf.math.exp(-0.1)\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "#EARLY STOPPING\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
        "\n",
        "#TENSORBOARD PLOTS\n",
        "tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir='logs')\n",
        "\n",
        "#SAVE MODEL WEIGHTS\n",
        "class SaveModel(tf.keras.callbacks.Callback):\n",
        "\n",
        "  def __init__(self):\n",
        "    self.history = { 'loss' : [],  'val_loss' : []}\n",
        "    self.init = 0\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs = {}):\n",
        "    \n",
        "    self.history['loss'].append(logs.get('loss'))\n",
        "    if logs.get('val_loss', -1) != -1:\n",
        "        self.history['val_loss'].append(logs.get('val_loss'))\n",
        "\n",
        "    #if epochs % 10 == 0:\n",
        "    self.model.save_weights('/content/drive/MyDrive/Data/ENC_DEC_EMB/weights_{}.h5'.format(epoch+self.init))    #print('Saved weights for epoch {}!'.format(epoch))\n",
        "\n",
        "    df = pd.DataFrame(columns = ['loss','val_loss']) \n",
        "    for col in df.columns:\n",
        "      df[col] = self.history[col]\n",
        "    df.to_csv('history.csv')\n",
        "    !cp history.csv \"/content/drive/MyDrive/Data/ENC_DEC_EMB/history.csv\"\n",
        "\n",
        "save_model = SaveModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "f5zcbJXLwaiN"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none'\n",
        ")\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "yoS9nmMYwedb"
      },
      "outputs": [],
      "source": [
        "def f_beta_score(y_true, y_pred):\n",
        "  y_pred_sparse = tf.convert_to_tensor(np.argmax(y_pred, axis = -1), dtype = tf.float32)\n",
        "  fb_score = [ fbeta_score(y_true[i], y_pred_sparse[i],average = 'macro',beta = 0.5) for i in range(y_true.shape[0])]#tf.py_function(fbeta_score, inp = [y, y_pred, 0.5], Tout=tf.float32)\n",
        "  return sum(fb_score)/len(fb_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OurUC7gwjwT"
      },
      "outputs": [],
      "source": [
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "#Create an object of encoder_decoder Model class, \n",
        "# Compile the model and fit the model\n",
        "input = np.random.randint(0, 64, size=(BATCH_SIZE, INPUT_ENCODER_LENGTH))\n",
        "output = np.random.randint(0, 64, size=(BATCH_SIZE, INPUT_DECODER_LENGTH))\n",
        "target = np.random.randint(0, 64, size=(BATCH_SIZE, INPUT_DECODER_LENGTH))#tf.keras.utils.to_categorical(output, OUTPUT_VOCAB_SIZE)\n",
        "\n",
        "model = Encoder_decoder(encoder_inputs_length = INPUT_ENCODER_LENGTH, decoder_inputs_length =INPUT_DECODER_LENGTH, output_vocab_size= OUTPUT_VOCAB_SIZE)\n",
        "#model = encoder_decoder(enc_units = 1024, dec_units = 1024, scoring_func = 'dot', att_units = 1024)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),loss=loss_function, metrics = [f_beta_score])#tf.keras.metrics.categorical_crossentropy)\n",
        "model.fit([input, output], target, steps_per_epoch=1)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FU-TBUfAwnfH"
      },
      "outputs": [],
      "source": [
        "model.fit(train_dataset,\n",
        "          validation_data = test_dataset, \n",
        "          epochs = 50, \n",
        "          callbacks = [early_stopping,tensorboard_cb, save_model])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset,\n",
        "          validation_data = test_dataset, \n",
        "          epochs = 50, \n",
        "          callbacks = [early_stopping,tensorboard_cb, save_model])"
      ],
      "metadata": {
        "id": "AaN6EQphO2v-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "efKO3XMaO5iO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('drive/MyDrive/GEC/ENC_DEC_EMB/weights_24_best.h5')"
      ],
      "metadata": {
        "id": "TzE_3Gt0O9gD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def input_processor(input_sentence, pad_seq):\n",
        "\n",
        "  #Preprocess to remove unwanted characters and convert to ASCII characters\n",
        "  encoder_input = preprocess(input_sentence, add_start_token= True, add_end_token=True)\n",
        "\n",
        "  #Convert to sequence\n",
        "  tokenized_text = tokenizer.texts_to_sequences([encoder_input])\n",
        "  if pad_seq == True:\n",
        "    tokenized_text = pad_sequences(tokenized_text, maxlen=INPUT_ENCODER_LENGTH, padding=\"post\")\n",
        "\n",
        "  tokenized_text = tf.convert_to_tensor(tokenized_text, dtype = tf.float32)\n",
        "  return tokenized_text\n",
        "\n",
        "\n",
        "def remove_end_token(words):\n",
        "  words_list = words.split(' ')[:-1]\n",
        "  words = \" \".join(words_list)\n",
        "  return words"
      ],
      "metadata": {
        "id": "jlztVU9IPB0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(input_sentence):\n",
        "  input = input_processor(input_sentence, pad_seq = False)\n",
        "\n",
        "  INPUT_LENGTH = input.shape[0] #Or number of inputs\n",
        "\n",
        "  states = model.layers[0].initialize_states(INPUT_LENGTH)\n",
        "\n",
        "  encoder_output,encoder_final_state_h,encoder_final_state_c = model.layers[0](input, states)\n",
        "  states = [encoder_final_state_h,encoder_final_state_c]  #States to initialize Decoder with\n",
        "\n",
        "  input_decoder = np.zeros((1,1))\n",
        "  input_decoder[0][0] = 2  #<start> for eng vocab\n",
        "  \n",
        "  decoder_output_list = []\n",
        "  stop = False\n",
        "\n",
        "  while stop != True :\n",
        "\n",
        "    decoder_output, dec_final_state_h, dec_final_state_c = model.layers[1](input_decoder, states)\n",
        "    \n",
        "    states = [dec_final_state_h, dec_final_state_c]\n",
        "\n",
        "    output = model.layers[2](decoder_output)\n",
        "\n",
        "    index = np.argmax(output, -1)\n",
        "    decoder_output_list.append(index)\n",
        "    input_decoder = index\n",
        "\n",
        "    if index[0][0] == 4 :#or len(decoder_output_list) > input.shape[1]: #Index of <end> for out_tokenizer\n",
        "      stop =True\n",
        "\n",
        "  #Get the output tokens and store in arr_out\n",
        "  arr_out = [int(np.asarray(i)[0][0]) for i in decoder_output_list]\n",
        "\n",
        "  #Convert to text\n",
        "  output_words = out_tokenizer.sequences_to_texts([arr_out])\n",
        "\n",
        "  return output_words\n",
        "  "
      ],
      "metadata": {
        "id": "mNDPKSMDPEZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices = [random.randint(0, 10000) for i in range(1000)]\n",
        "sent_list = [data['error'].iloc[i] for i in indices]\n",
        "bleu_scores_ = []\n",
        "actual_output = []\n",
        "output_sent_list = []\n",
        "\n",
        "print(sent_list)\n",
        "\n",
        "#Translate and calculate BLEU scores\n",
        "for i, sent in enumerate(tqdm(sent_list)):\n",
        "  out = predict(sent) \n",
        "  actual_ = decoder_output[indices[i]]\n",
        "\n",
        "  output_sent_list.append(out[0])\n",
        "  actual_output.append(actual_)\n",
        "\n",
        "  #Remove <end> token\n",
        "  out_words = remove_end_token(out[0])\n",
        "  actual_output_ = remove_end_token(actual_)\n",
        "\n",
        "  #Calculate BLEU scores\n",
        "  bleu_scores_.append(sentence_bleu(actual_output_.split(' '), out_words.split(' ')))\n",
        "\n",
        "\n",
        "print('Average BLEU score :',sum(bleu_scores_)/len(bleu_scores_))"
      ],
      "metadata": {
        "id": "HdhkM1KLPFWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(columns= ['input_sentence', 'actual_output','translated_output', 'bleu_score'])\n",
        "df['input_sentence'] = sent_list\n",
        "df['actual_output'] = actual_output\n",
        "df['translated_output'] = output_sent_list\n",
        "df['bleu_score'] = bleu_scores_"
      ],
      "metadata": {
        "id": "toIWbIf0PJAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('drive/MyDrive/GEC/ENC_DEC/weights_49_.h5')"
      ],
      "metadata": {
        "id": "VI-GB4FVPMlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices = [random.randint(0, 10000) for i in range(1000)]\n",
        "sent_list = [data['error'].iloc[i] for i in indices]\n",
        "bleu_scores_ = []\n",
        "actual_output = []\n",
        "output_sent_list = []\n",
        "\n",
        "print(sent_list)\n",
        "\n",
        "#Translate and calculate BLEU scores\n",
        "for i, sent in enumerate(tqdm(sent_list)):\n",
        "  out = predict(sent) \n",
        "  actual_ = decoder_output[indices[i]]\n",
        "\n",
        "  output_sent_list.append(out[0])\n",
        "  actual_output.append(actual_)\n",
        "\n",
        "  #Remove <end> token\n",
        "  out_words = remove_end_token(out[0])\n",
        "  actual_output_ = remove_end_token(actual_)\n",
        "\n",
        "  #Calculate BLEU scores\n",
        "  bleu_scores_.append(sentence_bleu(actual_output_.split(' '), out_words.split(' ')))\n",
        "\n",
        "\n",
        "print('Average BLEU score :',sum(bleu_scores_)/len(bleu_scores_))"
      ],
      "metadata": {
        "id": "u14uC2SYPVvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(columns= ['input_sentence', 'actual_output','translated_output', 'bleu_score'])\n",
        "df['input_sentence'] = sent_list\n",
        "df['actual_output'] = actual_output\n",
        "df['translated_output'] = output_sent_list\n",
        "df['bleu_score'] = bleu_scores_"
      ],
      "metadata": {
        "id": "bndHecIvPY2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[:50]"
      ],
      "metadata": {
        "id": "Zfh3ewcgPb6i"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Data_cleaning_and_sorting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPWcsONXWPhNTiLt6KNLFiP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}